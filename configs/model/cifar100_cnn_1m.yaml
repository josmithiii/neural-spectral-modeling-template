_target_: src.models.mnist_module.MNISTLitModule

optimizer:
  _target_: torch.optim.Adam
  _partial_: true
  lr: 0.001
  weight_decay: 0.0001

scheduler:
  _target_: torch.optim.lr_scheduler.ReduceLROnPlateau
  _partial_: true
  mode: min
  factor: 0.1
  patience: 10

criterion:
  _target_: torch.nn.CrossEntropyLoss

net:
  _target_: src.models.components.simple_cnn.SimpleCNN
  input_channels: 3  # CIFAR-100 has 3 color channels
  conv1_channels: 88  # Increased from 64 for more parameters
  conv2_channels: 176  # Increased from 128 for more parameters
  fc_hidden: 320  # Adjusted to reach ~1M total parameters
  output_size: 100  # CIFAR-100 has 100 fine-grained classes
  dropout: 0.5  # Higher dropout for more challenging dataset
  input_size: 32  # CIFAR image size

# compile model for faster training with pytorch 2.0
compile: false
