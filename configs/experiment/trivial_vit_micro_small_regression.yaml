# @package _global_

# Micro ViT on small (256 samples) trivial dataset â€” regression variant (placeholder)
# Note: VisionTransformer currently outputs classification logits; a true regression ViT
#       would require regression heads. This keeps naming parity for convenience.
# Run: python src/train.py experiment=trivial_vit_micro_small_regression

defaults:
  - override /data: vimh
  - override /model: vit_micro_regression
  - override /callbacks: default
  - override /trainer: default

# Callbacks configuration for regression mode
callbacks:
  model_checkpoint:
    _target_: lightning.pytorch.callbacks.ModelCheckpoint
    monitor: "val/loss"
    mode: "min"
    save_top_k: 1
    save_last: true
    verbose: false
    dirpath: ${paths.log_dir}/checkpoints
    filename: "best"
  early_stopping:
    _target_: lightning.pytorch.callbacks.EarlyStopping
    monitor: "val/loss" # or "mae_best", "val/note_number_mae", etc.
    patience: 10
    verbose: false
    mode: "min"

tags: ["trivial", "vit", "micro", "small_data", "regression-placeholder"]

seed: 12345

trainer:
  min_epochs: 3
  max_epochs: 8

model:
  optimizer:
    lr: 0.005
    weight_decay: 0.01

data:
  data_dir: data/vimh-32x32x1_8000Hz_1p0s_256dss_simple_2p
  batch_size: 32

# Optimized metric for regression mode
optimized_metric: "val/loss"

logger:
  tensorboard:
    name: "trivial_vit_micro_small_regression"
