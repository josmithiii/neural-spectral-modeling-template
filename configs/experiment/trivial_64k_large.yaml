# @package _global_

# "64K" CNN (actually 1.4M) on large (16K samples) trivial dataset - for comparison
# python src/train.py experiment=trivial_64k_large

defaults:
  - override /data: vimh
  - override /model: cnn_64k
  - override /callbacks: default
  - override /trainer: default

tags: ["trivial", "oversized", "large_data"]

seed: 12345

trainer:
  min_epochs: 3
  max_epochs: 5  # Should overfit immediately

model:
  optimizer:
    lr: 0.001
    weight_decay: 0.0001

data:
  data_dir: data/vimh-32x32x1_8000Hz_1p0s_16384dss_simple_2p
  batch_size: 128  # Larger batches for oversized model

logger:
  tensorboard:
    name: "trivial_64k_large"