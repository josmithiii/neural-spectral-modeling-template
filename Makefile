h help:  ## Show help
	@grep -E '^[.a-zA-Z0-9_ -]+:.*?## .*$$' $(MAKEFILE_LIST) | awk 'BEGIN {FS = ":.*?## "}; {printf "\033[36m%-30s\033[0m %s\n", $$1, $$2}'

# SYNTHETIC DATASET MAKE TARGETS "sd"

sds synth-dataset-small: ## Synthesize a small example VIMH dataset (256 samples)
	python generate_vimh.py --config-name=generate_simple_saw
	ls ./data/

sdl synth-dataset-large: ## Synthesize a larger example VIMH dataset (16k samples)
	python generate_vimh.py --config-name=generate_simple_saw dataset.size=16384
	ls ./data/

# DISPLAY VIMH DATASETS "dd"

ddr display-dataset-recent: ## Display the most recently created dataset (default)
	python display_vimh.py

dds display-dataset-small: ## Display the small example VIMH dataset (256 samples)
	python display_vimh.py data/vimh-32x32x1_8000Hz_1p0s_256dss_simple_2p

ddl display-dataset-large: ## Display the larger example VIMH dataset (16k samples)
	python display_vimh.py data/vimh-32x32x1_8000Hz_1p0s_16384dss_simple_2p

# EXPERIMENTS "e" - Complete Configuration Examples

ex exp-example: ## Train CNN on default dataset
	time python src/train.py experiment=example  # ./configs/experiment/example.yaml

# TRIVIAL DATASET EXPERIMENTS "et" - Small models for testing on trivial synthetic data

etms exp-trivial-micro-small: ## Micro CNN (~2K params) on small dataset (256 samples)
	time python src/train.py experiment=trivial_micro_small

etts exp-trivial-tiny-small: ## Tiny CNN (~8K params) on small dataset (256 samples)
	time python src/train.py experiment=trivial_tiny_small

etml exp-trivial-micro-large: ## Micro CNN (~2K params) on large dataset (16K samples)
	time python src/train.py experiment=trivial_micro_large

ettl exp-trivial-tiny-large: ## Tiny CNN (~8K params) on large dataset (16K samples)
	time python src/train.py experiment=trivial_tiny_large

et64l exp-trivial-64k-large: ## "64K" CNN (actually 1.4M params) on large dataset - for comparison
	time python src/train.py experiment=trivial_64k_large

etall: ex etms etts etml ettl et64l ## Run all trivial dataset experiments: ex etms etts etml ettl et64l

# CLEANING MAKE TARGETS

dc dclean: ## Clean data files
	rm -rf data/*

cl clean-logs: ## Clean logs
	rm -rf logs/**

c clean: ## Clean all autogenerated files
	rm -rf dist
	find . -type f -name "*.DS_Store" -ls -delete
	find . | grep -E "(__pycache__|\.pyc|\.pyo)" | xargs rm -rf
	find . | grep -E ".pytest_cache" | xargs rm -rf
	find . | grep -E ".ipynb_checkpoints" | xargs rm -rf
	rm -f .coverage
	rm -rf ./viz/diagrams
	rm -rf ./outputs/

# TESTING TARGETS "t"

t test: ## Run fast pytest tests
	pytest -k "not slow"

ta test-all: ## Run all pytest tests
	pytest

td test-diagram: ## Generate model architecture diagrams (text + graphical)
	python viz/enhanced_model_diagrams.py

tda test-diagram-all: ## Generate diagrams for all VIMH model architectures
	python viz/enhanced_model_diagrams.py -c cnn_64k
	python viz/enhanced_model_diagrams.py -c cnn_64k_ordinal
	python viz/enhanced_model_diagrams.py -c cnn_64k_regression
	python viz/enhanced_model_diagrams.py -c cnn_stk

tdl test-diagram-list: ## List available model configs for diagrams
	python viz/enhanced_model_diagrams.py --list-configs

tds test-diagram-simple: ## Generate simple text-only diagrams (default cnn_64k)
	python viz/simple_model_diagram.py

tdsc test-diagram-simple-config: ## Generate simple diagram for specific config (usage: make tdsc CONFIG=cnn_64k)
	python viz/simple_model_diagram.py --config $(CONFIG)

tdsl test-diagram-simple-list: ## List available configs for simple diagrams
	python viz/simple_model_diagram.py --list-configs

tdss test-diagram-simple-samples: ## Generate simple diagrams for VIMH architectures
	@echo "=== VIMH CNN (64K params) ==="
	python viz/simple_model_diagram.py --config cnn_64k
	@echo "\n=== VIMH CNN Ordinal (64K params) ==="
	python viz/simple_model_diagram.py --config cnn_64k_ordinal
	@echo "\n=== VIMH CNN Regression (64K params) ==="
	python viz/simple_model_diagram.py --config cnn_64k_regression
	@echo "\n=== VIMH CNN STK ==="
	python viz/simple_model_diagram.py --config cnn_stk

# UTILITY TARGETS

f format: ## Run pre-commit hooks
	pre-commit run -a

s sync: ## Merge changes from main branch to your current branch
	git pull
	git pull origin main

tb tensorboard: ## Launch TensorBoard on port 6006
	@lsof -i :6006 >/dev/null 2>&1 && echo "TensorBoard already running on port 6006" || \
		(echo "Starting TensorBoard on port 6006..." && tensorboard --logdir logs/ --reload_interval 1 --port 6006 &)
	@echo "Open http://localhost:6006/"

a activate: ## Activate the uv environment
	@echo "Add to ~/.tcshrc: alias a 'echo \"source .venv/bin/activate.csh\" && source .venv/bin/activate.csh'"
	@echo "Then just type: a"

d deactivate: ## Deactivate the uv environment
	@echo "Add to ~/.tcshrc: alias d 'echo deactivate && deactivate'"
	@echo "Then just type: d"

lc list-configs: ## List available model configurations
	@echo "Available model configs:"
	@find configs/model -name "*.yaml" | sed 's|configs/model/||' | sed 's|\.yaml||' | sort
	@echo "\nAvailable data configs:"  
	@find configs/data -name "*.yaml" | sed 's|configs/data/||' | sed 's|\.yaml||' | sort
	@echo "\nAvailable experiment configs:"
	@find configs/experiment -name "*.yaml" | sed 's|configs/experiment/||' | sed 's|\.yaml||' | sort

# TRAINING TARGETS "tr" (no "experiment" - use hydra overrides to set desired config)

tr train: ## Train default model on default dataset (`make tr`) - defaults defined in ./configs/train.yaml
	time python src/train.py

trq train-quick: ## Train super quickly the default model and dataset (quick sanity test to see if things are working)
	python src/train.py trainer.max_epochs=1

trs train-vimh-small: ## Train the small example VIMH dataset using the default model (CNN 64k)
	time python src/train.py data.data_dir=data/vimh-32x32x1_8000Hz_1p0s_256dss_simple_2p

trl train-vimh-large: ## Train the large example VIMH dataset using the default model (CNN 64k)
	time python src/train.py data.data_dir=data/vimh-32x32x1_8000Hz_1p0s_16384dss_simple_2p

