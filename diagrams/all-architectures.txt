python viz/enhanced_model_diagrams.py
Generating diagrams for all 9 model configs...

[1/9] Processing cnn_64k...

Generating diagrams from config: cnn_64k
Using input shape: (1, 1, 32, 32)
================================================================================
Model: cnn_64k Architecture Summary
================================================================================

Model Structure:
MultiheadLitModule(
  (net): SimpleCNN(
    (conv_layers): Sequential(
      (0): Conv2d(1, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU()
      (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
      (4): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (5): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (6): ReLU()
      (7): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
      (8): AdaptiveAvgPool2d(output_size=(4, 4))
    )
    (shared_features): Sequential(
      (0): Flatten(start_dim=1, end_dim=-1)
      (1): Linear(in_features=2048, out_features=512, bias=True)
      (2): ReLU()
      (3): Dropout(p=0.5, inplace=False)
    )
    (classifier): Linear(in_features=512, out_features=10, bias=True)
  )
)

Parameter Count:
Total parameters: 1,129,098
Trainable parameters: 1,129,098

Forward Pass Shape Analysis:
Input shape: (1, 1, 32, 32)
Input: torch.Size([1, 1, 32, 32])
Final output: torch.Size([1, 10])

================================================================================
CNN Architecture Flow Diagram
================================================================================

    Input (1×28×28) MNIST Image
           │
           ▼
    ┌─────────────────────────────┐
    │     CONV BLOCK 1            │
    │  Conv2d(1→3, 3×3, pad=1)    │  ← 3×3 convolution
    │  BatchNorm2d(3)             │  ← normalize activations
    │  ReLU()                     │  ← activation function
    │  MaxPool2d(2×2, stride=2)   │  ← downsample by 2
    └─────────────────────────────┘
           │ (3×14×14)
           ▼
    ┌─────────────────────────────┐
    │     CONV BLOCK 2            │
    │  Conv2d(3→6, 3×3, pad=1)    │  ← double channels
    │  BatchNorm2d(6)             │  ← normalize activations
    │  ReLU()                     │  ← activation function
    │  MaxPool2d(2×2, stride=2)   │  ← downsample by 2
    └─────────────────────────────┘
           │ (6×7×7)
           ▼
    ┌─────────────────────────────┐
    │   FEATURE EXTRACTION        │
    │  AdaptiveAvgPool2d(7×7)     │  ← ensure 7×7 output
    │  Flatten()                  │  ← reshape to 1D
    └─────────────────────────────┘
           │ (294,) = 6×7×7
           ▼
    ┌─────────────────────────────┐
    │    CLASSIFIER HEAD          │
    │  Linear(294→25)             │  ← hidden layer
    │  ReLU()                     │  ← activation
    │  Dropout(0.25)              │  ← regularization
    │  Linear(25→10)              │  ← output layer
    └─────────────────────────────┘
           │
           ▼
        Output (10,) Class Logits
    

Generating graphical diagram for cnn_64k...
Saved graphical diagrams:
  PNG: diagrams/cnn_64k_graph.png
  PDF: diagrams/cnn_64k_graph.pdf

[2/9] Processing cnn_64k_regression...

Generating diagrams from config: cnn_64k_regression
Using input shape: (1, 3, 32, 32)
================================================================================
Model: cnn_64k_regression Architecture Summary
================================================================================

Model Structure:
MultiheadLitModule(
  (net): SimpleCNN(
    (conv_layers): Sequential(
      (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU()
      (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
      (4): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (5): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (6): ReLU()
      (7): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
      (8): AdaptiveAvgPool2d(output_size=(4, 4))
    )
    (shared_features): Sequential(
      (0): Flatten(start_dim=1, end_dim=-1)
      (1): Linear(in_features=2048, out_features=512, bias=True)
      (2): ReLU()
      (3): Dropout(p=0.5, inplace=False)
    )
    (classifier): Sequential(
      (0): Linear(in_features=512, out_features=1, bias=True)
      (1): Sigmoid()
    )
  )
)

Parameter Count:
Total parameters: 1,125,633
Trainable parameters: 1,125,633

Forward Pass Shape Analysis:
Input shape: (1, 3, 32, 32)
Input: torch.Size([1, 3, 32, 32])
Final output: torch.Size([1, 1])

================================================================================
CNN Architecture Flow Diagram
================================================================================

    Input (1×28×28) MNIST Image
           │
           ▼
    ┌─────────────────────────────┐
    │     CONV BLOCK 1            │
    │  Conv2d(1→3, 3×3, pad=1)    │  ← 3×3 convolution
    │  BatchNorm2d(3)             │  ← normalize activations
    │  ReLU()                     │  ← activation function
    │  MaxPool2d(2×2, stride=2)   │  ← downsample by 2
    └─────────────────────────────┘
           │ (3×14×14)
           ▼
    ┌─────────────────────────────┐
    │     CONV BLOCK 2            │
    │  Conv2d(3→6, 3×3, pad=1)    │  ← double channels
    │  BatchNorm2d(6)             │  ← normalize activations
    │  ReLU()                     │  ← activation function
    │  MaxPool2d(2×2, stride=2)   │  ← downsample by 2
    └─────────────────────────────┘
           │ (6×7×7)
           ▼
    ┌─────────────────────────────┐
    │   FEATURE EXTRACTION        │
    │  AdaptiveAvgPool2d(7×7)     │  ← ensure 7×7 output
    │  Flatten()                  │  ← reshape to 1D
    └─────────────────────────────┘
           │ (294,) = 6×7×7
           ▼
    ┌─────────────────────────────┐
    │    CLASSIFIER HEAD          │
    │  Linear(294→25)             │  ← hidden layer
    │  ReLU()                     │  ← activation
    │  Dropout(0.25)              │  ← regularization
    │  Linear(25→10)              │  ← output layer
    └─────────────────────────────┘
           │
           ▼
        Output (10,) Class Logits
    

Generating graphical diagram for cnn_64k_regression...
Saved graphical diagrams:
  PNG: diagrams/cnn_64k_regression_graph.png
  PDF: diagrams/cnn_64k_regression_graph.pdf

[3/9] Processing cnn_micro...

Generating diagrams from config: cnn_micro
Using input shape: (1, 1, 32, 32)
================================================================================
Model: cnn_micro Architecture Summary
================================================================================

Model Structure:
MultiheadLitModule(
  (net): SimpleCNN(
    (conv_layers): Sequential(
      (0): Conv2d(1, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (1): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU()
      (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
      (4): Conv2d(8, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (5): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (6): ReLU()
      (7): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
      (8): AdaptiveAvgPool2d(output_size=(4, 4))
    )
    (shared_features): Sequential(
      (0): Flatten(start_dim=1, end_dim=-1)
      (1): Linear(in_features=256, out_features=32, bias=True)
      (2): ReLU()
      (3): Dropout(p=0.2, inplace=False)
    )
    (classifier): Linear(in_features=32, out_features=10, bias=True)
  )
)

Parameter Count:
Total parameters: 9,850
Trainable parameters: 9,850

Forward Pass Shape Analysis:
Input shape: (1, 1, 32, 32)
Input: torch.Size([1, 1, 32, 32])
Final output: torch.Size([1, 10])

================================================================================
CNN Architecture Flow Diagram
================================================================================

    Input (1×28×28) MNIST Image
           │
           ▼
    ┌─────────────────────────────┐
    │     CONV BLOCK 1            │
    │  Conv2d(1→3, 3×3, pad=1)    │  ← 3×3 convolution
    │  BatchNorm2d(3)             │  ← normalize activations
    │  ReLU()                     │  ← activation function
    │  MaxPool2d(2×2, stride=2)   │  ← downsample by 2
    └─────────────────────────────┘
           │ (3×14×14)
           ▼
    ┌─────────────────────────────┐
    │     CONV BLOCK 2            │
    │  Conv2d(3→6, 3×3, pad=1)    │  ← double channels
    │  BatchNorm2d(6)             │  ← normalize activations
    │  ReLU()                     │  ← activation function
    │  MaxPool2d(2×2, stride=2)   │  ← downsample by 2
    └─────────────────────────────┘
           │ (6×7×7)
           ▼
    ┌─────────────────────────────┐
    │   FEATURE EXTRACTION        │
    │  AdaptiveAvgPool2d(7×7)     │  ← ensure 7×7 output
    │  Flatten()                  │  ← reshape to 1D
    └─────────────────────────────┘
           │ (294,) = 6×7×7
           ▼
    ┌─────────────────────────────┐
    │    CLASSIFIER HEAD          │
    │  Linear(294→25)             │  ← hidden layer
    │  ReLU()                     │  ← activation
    │  Dropout(0.25)              │  ← regularization
    │  Linear(25→10)              │  ← output layer
    └─────────────────────────────┘
           │
           ▼
        Output (10,) Class Logits
    

Generating graphical diagram for cnn_micro...
Saved graphical diagrams:
  PNG: diagrams/cnn_micro_graph.png
  PDF: diagrams/cnn_micro_graph.pdf

[4/9] Processing cnn_tiny...

Generating diagrams from config: cnn_tiny
Using input shape: (1, 1, 32, 32)
================================================================================
Model: cnn_tiny Architecture Summary
================================================================================

Model Structure:
MultiheadLitModule(
  (net): SimpleCNN(
    (conv_layers): Sequential(
      (0): Conv2d(1, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU()
      (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
      (4): Conv2d(16, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (5): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (6): ReLU()
      (7): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
      (8): AdaptiveAvgPool2d(output_size=(4, 4))
    )
    (shared_features): Sequential(
      (0): Flatten(start_dim=1, end_dim=-1)
      (1): Linear(in_features=512, out_features=64, bias=True)
      (2): ReLU()
      (3): Dropout(p=0.3, inplace=False)
    )
    (classifier): Linear(in_features=64, out_features=10, bias=True)
  )
)

Parameter Count:
Total parameters: 38,378
Trainable parameters: 38,378

Forward Pass Shape Analysis:
Input shape: (1, 1, 32, 32)
Input: torch.Size([1, 1, 32, 32])
Final output: torch.Size([1, 10])

================================================================================
CNN Architecture Flow Diagram
================================================================================

    Input (1×28×28) MNIST Image
           │
           ▼
    ┌─────────────────────────────┐
    │     CONV BLOCK 1            │
    │  Conv2d(1→3, 3×3, pad=1)    │  ← 3×3 convolution
    │  BatchNorm2d(3)             │  ← normalize activations
    │  ReLU()                     │  ← activation function
    │  MaxPool2d(2×2, stride=2)   │  ← downsample by 2
    └─────────────────────────────┘
           │ (3×14×14)
           ▼
    ┌─────────────────────────────┐
    │     CONV BLOCK 2            │
    │  Conv2d(3→6, 3×3, pad=1)    │  ← double channels
    │  BatchNorm2d(6)             │  ← normalize activations
    │  ReLU()                     │  ← activation function
    │  MaxPool2d(2×2, stride=2)   │  ← downsample by 2
    └─────────────────────────────┘
           │ (6×7×7)
           ▼
    ┌─────────────────────────────┐
    │   FEATURE EXTRACTION        │
    │  AdaptiveAvgPool2d(7×7)     │  ← ensure 7×7 output
    │  Flatten()                  │  ← reshape to 1D
    └─────────────────────────────┘
           │ (294,) = 6×7×7
           ▼
    ┌─────────────────────────────┐
    │    CLASSIFIER HEAD          │
    │  Linear(294→25)             │  ← hidden layer
    │  ReLU()                     │  ← activation
    │  Dropout(0.25)              │  ← regularization
    │  Linear(25→10)              │  ← output layer
    └─────────────────────────────┘
           │
           ▼
        Output (10,) Class Logits
    

Generating graphical diagram for cnn_tiny...
Saved graphical diagrams:
  PNG: diagrams/cnn_tiny_graph.png
  PDF: diagrams/cnn_tiny_graph.pdf

[5/9] Processing vit_micro...

Generating diagrams from config: vit_micro
Using input shape: (1, 1, 32, 32)
================================================================================
Model: vit_micro Architecture Summary
================================================================================

Model Structure:
MultiheadLitModule(
  (net): VisionTransformer(
    (embedding): EmbedLayer(
      (conv1): Conv2d(1, 32, kernel_size=(8, 8), stride=(8, 8))
      (dropout): Dropout(p=0.2, inplace=False)
    )
    (encoder): ModuleList(
      (0-1): 2 x Encoder(
        (norm1): LayerNorm((32,), eps=1e-05, elementwise_affine=True)
        (attention): SelfAttention(
          (queries): Linear(in_features=32, out_features=32, bias=True)
          (keys): Linear(in_features=32, out_features=32, bias=True)
          (values): Linear(in_features=32, out_features=32, bias=True)
          (out_projection): Linear(in_features=32, out_features=32, bias=True)
        )
        (dropout1): Dropout(p=0.2, inplace=False)
        (norm2): LayerNorm((32,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=32, out_features=64, bias=True)
        (activation): GELU(approximate='none')
        (fc2): Linear(in_features=64, out_features=32, bias=True)
        (dropout2): Dropout(p=0.2, inplace=False)
      )
    )
    (norm): LayerNorm((32,), eps=1e-05, elementwise_affine=True)
    (classifier): Classifier(
      (fc1): Linear(in_features=32, out_features=32, bias=True)
      (activation): Tanh()
      (fc2): Linear(in_features=32, out_features=10, bias=True)
    )
  )
)

Parameter Count:
Total parameters: 21,162
Trainable parameters: 21,162

Forward Pass Shape Analysis:
Input shape: (1, 1, 32, 32)
Input: torch.Size([1, 1, 32, 32])
Final output: torch.Size([1, 10])

================================================================================
CNN Architecture Flow Diagram
================================================================================

    Input (1×28×28) MNIST Image
           │
           ▼
    ┌─────────────────────────────┐
    │     CONV BLOCK 1            │
    │  Conv2d(1→3, 3×3, pad=1)    │  ← 3×3 convolution
    │  BatchNorm2d(3)             │  ← normalize activations
    │  ReLU()                     │  ← activation function
    │  MaxPool2d(2×2, stride=2)   │  ← downsample by 2
    └─────────────────────────────┘
           │ (3×14×14)
           ▼
    ┌─────────────────────────────┐
    │     CONV BLOCK 2            │
    │  Conv2d(3→6, 3×3, pad=1)    │  ← double channels
    │  BatchNorm2d(6)             │  ← normalize activations
    │  ReLU()                     │  ← activation function
    │  MaxPool2d(2×2, stride=2)   │  ← downsample by 2
    └─────────────────────────────┘
           │ (6×7×7)
           ▼
    ┌─────────────────────────────┐
    │   FEATURE EXTRACTION        │
    │  AdaptiveAvgPool2d(7×7)     │  ← ensure 7×7 output
    │  Flatten()                  │  ← reshape to 1D
    └─────────────────────────────┘
           │ (294,) = 6×7×7
           ▼
    ┌─────────────────────────────┐
    │    CLASSIFIER HEAD          │
    │  Linear(294→25)             │  ← hidden layer
    │  ReLU()                     │  ← activation
    │  Dropout(0.25)              │  ← regularization
    │  Linear(25→10)              │  ← output layer
    └─────────────────────────────┘
           │
           ▼
        Output (10,) Class Logits
    

Generating graphical diagram for vit_micro...
Saved graphical diagrams:
  PNG: diagrams/vit_micro_graph.png
  PDF: diagrams/vit_micro_graph.pdf

[6/9] Processing cnn_64k_auxiliary...

Generating diagrams from config: cnn_64k_auxiliary
Using input shape: (1, 1, 32, 32)
================================================================================
Model: cnn_64k_auxiliary Architecture Summary
================================================================================

Model Structure:
MultiheadLitModule(
  (net): SimpleCNN(
    (conv_layers): Sequential(
      (0): Conv2d(1, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU()
      (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
      (4): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (5): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (6): ReLU()
      (7): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
      (8): AdaptiveAvgPool2d(output_size=(4, 4))
    )
    (shared_features): Sequential(
      (0): Flatten(start_dim=1, end_dim=-1)
      (1): Linear(in_features=2048, out_features=512, bias=True)
      (2): ReLU()
      (3): Dropout(p=0.5, inplace=False)
    )
    (classifier): Linear(in_features=512, out_features=10, bias=True)
  )
)

Parameter Count:
Total parameters: 1,129,098
Trainable parameters: 1,129,098

Forward Pass Shape Analysis:
Input shape: (1, 1, 32, 32)
Input: torch.Size([1, 1, 32, 32])
Final output: torch.Size([1, 10])

================================================================================
CNN Architecture Flow Diagram
================================================================================

    Input (1×28×28) MNIST Image
           │
           ▼
    ┌─────────────────────────────┐
    │     CONV BLOCK 1            │
    │  Conv2d(1→3, 3×3, pad=1)    │  ← 3×3 convolution
    │  BatchNorm2d(3)             │  ← normalize activations
    │  ReLU()                     │  ← activation function
    │  MaxPool2d(2×2, stride=2)   │  ← downsample by 2
    └─────────────────────────────┘
           │ (3×14×14)
           ▼
    ┌─────────────────────────────┐
    │     CONV BLOCK 2            │
    │  Conv2d(3→6, 3×3, pad=1)    │  ← double channels
    │  BatchNorm2d(6)             │  ← normalize activations
    │  ReLU()                     │  ← activation function
    │  MaxPool2d(2×2, stride=2)   │  ← downsample by 2
    └─────────────────────────────┘
           │ (6×7×7)
           ▼
    ┌─────────────────────────────┐
    │   FEATURE EXTRACTION        │
    │  AdaptiveAvgPool2d(7×7)     │  ← ensure 7×7 output
    │  Flatten()                  │  ← reshape to 1D
    └─────────────────────────────┘
           │ (294,) = 6×7×7
           ▼
    ┌─────────────────────────────┐
    │    CLASSIFIER HEAD          │
    │  Linear(294→25)             │  ← hidden layer
    │  ReLU()                     │  ← activation
    │  Dropout(0.25)              │  ← regularization
    │  Linear(25→10)              │  ← output layer
    └─────────────────────────────┘
           │
           ▼
        Output (10,) Class Logits
    

Generating graphical diagram for cnn_64k_auxiliary...
Saved graphical diagrams:
  PNG: diagrams/cnn_64k_auxiliary_graph.png
  PDF: diagrams/cnn_64k_auxiliary_graph.pdf

[7/9] Processing cnn_64k_ordinal...

Generating diagrams from config: cnn_64k_ordinal
Using input shape: (1, 3, 32, 32)
================================================================================
Model: cnn_64k_ordinal Architecture Summary
================================================================================

Model Structure:
MultiheadLitModule(
  (net): SimpleCNN(
    (conv_layers): Sequential(
      (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU()
      (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
      (4): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (5): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (6): ReLU()
      (7): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
      (8): AdaptiveAvgPool2d(output_size=(4, 4))
    )
    (shared_features): Sequential(
      (0): Flatten(start_dim=1, end_dim=-1)
      (1): Linear(in_features=2048, out_features=512, bias=True)
      (2): ReLU()
      (3): Dropout(p=0.5, inplace=False)
    )
    (classifier): Linear(in_features=512, out_features=10, bias=True)
  )
)

Parameter Count:
Total parameters: 1,130,250
Trainable parameters: 1,130,250

Forward Pass Shape Analysis:
Input shape: (1, 3, 32, 32)
Input: torch.Size([1, 3, 32, 32])
Final output: torch.Size([1, 10])

================================================================================
CNN Architecture Flow Diagram
================================================================================

    Input (1×28×28) MNIST Image
           │
           ▼
    ┌─────────────────────────────┐
    │     CONV BLOCK 1            │
    │  Conv2d(1→3, 3×3, pad=1)    │  ← 3×3 convolution
    │  BatchNorm2d(3)             │  ← normalize activations
    │  ReLU()                     │  ← activation function
    │  MaxPool2d(2×2, stride=2)   │  ← downsample by 2
    └─────────────────────────────┘
           │ (3×14×14)
           ▼
    ┌─────────────────────────────┐
    │     CONV BLOCK 2            │
    │  Conv2d(3→6, 3×3, pad=1)    │  ← double channels
    │  BatchNorm2d(6)             │  ← normalize activations
    │  ReLU()                     │  ← activation function
    │  MaxPool2d(2×2, stride=2)   │  ← downsample by 2
    └─────────────────────────────┘
           │ (6×7×7)
           ▼
    ┌─────────────────────────────┐
    │   FEATURE EXTRACTION        │
    │  AdaptiveAvgPool2d(7×7)     │  ← ensure 7×7 output
    │  Flatten()                  │  ← reshape to 1D
    └─────────────────────────────┘
           │ (294,) = 6×7×7
           ▼
    ┌─────────────────────────────┐
    │    CLASSIFIER HEAD          │
    │  Linear(294→25)             │  ← hidden layer
    │  ReLU()                     │  ← activation
    │  Dropout(0.25)              │  ← regularization
    │  Linear(25→10)              │  ← output layer
    └─────────────────────────────┘
           │
           ▼
        Output (10,) Class Logits
    

Generating graphical diagram for cnn_64k_ordinal...
Saved graphical diagrams:
  PNG: diagrams/cnn_64k_ordinal_graph.png
  PDF: diagrams/cnn_64k_ordinal_graph.pdf

[8/9] Processing cnn_stk...

Generating diagrams from config: cnn_stk
Using input shape: (1, 3, 32, 32)
================================================================================
Model: cnn_stk Architecture Summary
================================================================================

Model Structure:
MultiheadLitModule(
  (net): SimpleCNN(
    (conv_layers): Sequential(
      (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU()
      (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
      (4): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (5): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (6): ReLU()
      (7): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
      (8): AdaptiveAvgPool2d(output_size=(4, 4))
    )
    (shared_features): Sequential(
      (0): Flatten(start_dim=1, end_dim=-1)
      (1): Linear(in_features=2048, out_features=512, bias=True)
      (2): ReLU()
      (3): Dropout(p=0.5, inplace=False)
    )
    (classifier): Linear(in_features=512, out_features=256, bias=True)
  )
)

Parameter Count:
Total parameters: 1,256,448
Trainable parameters: 1,256,448

Forward Pass Shape Analysis:
Input shape: (1, 3, 32, 32)
Input: torch.Size([1, 3, 32, 32])
Final output: torch.Size([1, 256])

================================================================================
CNN Architecture Flow Diagram
================================================================================

    Input (1×28×28) MNIST Image
           │
           ▼
    ┌─────────────────────────────┐
    │     CONV BLOCK 1            │
    │  Conv2d(1→3, 3×3, pad=1)    │  ← 3×3 convolution
    │  BatchNorm2d(3)             │  ← normalize activations
    │  ReLU()                     │  ← activation function
    │  MaxPool2d(2×2, stride=2)   │  ← downsample by 2
    └─────────────────────────────┘
           │ (3×14×14)
           ▼
    ┌─────────────────────────────┐
    │     CONV BLOCK 2            │
    │  Conv2d(3→6, 3×3, pad=1)    │  ← double channels
    │  BatchNorm2d(6)             │  ← normalize activations
    │  ReLU()                     │  ← activation function
    │  MaxPool2d(2×2, stride=2)   │  ← downsample by 2
    └─────────────────────────────┘
           │ (6×7×7)
           ▼
    ┌─────────────────────────────┐
    │   FEATURE EXTRACTION        │
    │  AdaptiveAvgPool2d(7×7)     │  ← ensure 7×7 output
    │  Flatten()                  │  ← reshape to 1D
    └─────────────────────────────┘
           │ (294,) = 6×7×7
           ▼
    ┌─────────────────────────────┐
    │    CLASSIFIER HEAD          │
    │  Linear(294→25)             │  ← hidden layer
    │  ReLU()                     │  ← activation
    │  Dropout(0.25)              │  ← regularization
    │  Linear(25→10)              │  ← output layer
    └─────────────────────────────┘
           │
           ▼
        Output (10,) Class Logits
    

Generating graphical diagram for cnn_stk...
Saved graphical diagrams:
  PNG: diagrams/cnn_stk_graph.png
  PDF: diagrams/cnn_stk_graph.pdf

[9/9] Processing vit_tiny...

Generating diagrams from config: vit_tiny
Using input shape: (1, 1, 32, 32)
================================================================================
Model: vit_tiny Architecture Summary
================================================================================

Model Structure:
MultiheadLitModule(
  (net): VisionTransformer(
    (embedding): EmbedLayer(
      (conv1): Conv2d(1, 64, kernel_size=(4, 4), stride=(4, 4))
      (dropout): Dropout(p=0.3, inplace=False)
    )
    (encoder): ModuleList(
      (0-2): 3 x Encoder(
        (norm1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        (attention): SelfAttention(
          (queries): Linear(in_features=64, out_features=64, bias=True)
          (keys): Linear(in_features=64, out_features=64, bias=True)
          (values): Linear(in_features=64, out_features=64, bias=True)
          (out_projection): Linear(in_features=64, out_features=64, bias=True)
        )
        (dropout1): Dropout(p=0.3, inplace=False)
        (norm2): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=64, out_features=128, bias=True)
        (activation): GELU(approximate='none')
        (fc2): Linear(in_features=128, out_features=64, bias=True)
        (dropout2): Dropout(p=0.3, inplace=False)
      )
    )
    (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
    (classifier): Classifier(
      (fc1): Linear(in_features=64, out_features=64, bias=True)
      (activation): Tanh()
      (fc2): Linear(in_features=64, out_features=10, bias=True)
    )
  )
)

Parameter Count:
Total parameters: 110,602
Trainable parameters: 110,602

Forward Pass Shape Analysis:
Input shape: (1, 1, 32, 32)
Input: torch.Size([1, 1, 32, 32])
Final output: torch.Size([1, 10])

================================================================================
CNN Architecture Flow Diagram
================================================================================

    Input (1×28×28) MNIST Image
           │
           ▼
    ┌─────────────────────────────┐
    │     CONV BLOCK 1            │
    │  Conv2d(1→3, 3×3, pad=1)    │  ← 3×3 convolution
    │  BatchNorm2d(3)             │  ← normalize activations
    │  ReLU()                     │  ← activation function
    │  MaxPool2d(2×2, stride=2)   │  ← downsample by 2
    └─────────────────────────────┘
           │ (3×14×14)
           ▼
    ┌─────────────────────────────┐
    │     CONV BLOCK 2            │
    │  Conv2d(3→6, 3×3, pad=1)    │  ← double channels
    │  BatchNorm2d(6)             │  ← normalize activations
    │  ReLU()                     │  ← activation function
    │  MaxPool2d(2×2, stride=2)   │  ← downsample by 2
    └─────────────────────────────┘
           │ (6×7×7)
           ▼
    ┌─────────────────────────────┐
    │   FEATURE EXTRACTION        │
    │  AdaptiveAvgPool2d(7×7)     │  ← ensure 7×7 output
    │  Flatten()                  │  ← reshape to 1D
    └─────────────────────────────┘
           │ (294,) = 6×7×7
           ▼
    ┌─────────────────────────────┐
    │    CLASSIFIER HEAD          │
    │  Linear(294→25)             │  ← hidden layer
    │  ReLU()                     │  ← activation
    │  Dropout(0.25)              │  ← regularization
    │  Linear(25→10)              │  ← output layer
    └─────────────────────────────┘
           │
           ▼
        Output (10,) Class Logits
    

Generating graphical diagram for vit_tiny...
Saved graphical diagrams:
  PNG: diagrams/vit_tiny_graph.png
  PDF: diagrams/vit_tiny_graph.pdf

================================================================================
Model diagram generation complete!
Check the 'diagrams' directory for graphical outputs
================================================================================
