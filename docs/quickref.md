# Quick Reference

Expert power-user cheat sheet. No fluff.

## Make Targets (Essential)
```bash
# SETUP
make h            # Show all targets
make lc           # List configs

# QUICK TESTS (1 epoch, limited batches)
make tq           # Quick smoke test VIMH
make tqa          # All architectures quick

# TRAINING
make t            # Train with defaults
make tmps         # Train with MPS (Mac)
make tr           # Train CNN basic
make trcn         # Train ConvNeXt
make trv          # Train ViT

# EXPERIMENTS
make ex           # Example experiment
make emb          # Moog basic CNN
make eme          # Moog envelope CNN
make emr          # Moog resonance CNN

# VIMH DATASETS
make evimh        # VIMH CNN basic training
make evimh16k     # VIMH CNN 16K dataset
make evimho       # VIMH ordinal regression
make evimhr       # VIMH pure regression heads

# UTILITIES
make test         # Fast tests (exclude slow)
make test-all     # All tests including slow
make format       # Format code (pre-commit)
make clean        # Clean autogenerated files
make tensorboard  # Launch TensorBoard
```

## Architectures
| Name | Type | Params | Best For | Config |
|------|------|--------|----------|--------|
| CNN Micro | CNN | ~8K | Quick prototyping | `cnn_micro` |
| CNN 64K | CNN | ~64K | Standard spectral | `cnn_64k` |
| EfficientNet | CNN | Variable | Complex features | `efficientnet_*` |
| ViT | Transformer | Variable | Global patterns | `vit_*` |
| ConvNeXt | CNN | Variable | Modern CNN | `convnext_*` |

## Datasets
| Dataset | Size | Type | Use Case |
|---------|------|------|----------|
| VIMH-256 | 256 samples | Synthetic multihead | Quick prototyping |
| VIMH-16KDSS | 16K samples | Audio spectrograms | Full training |
| Moog VCF | Variable | Filter parameter regression | Audio synthesis |

## Common Commands
```bash
# Basic training with MPS (Mac)
python src/train.py trainer=mps

# Train with specific experiment
python src/train.py experiment=example

# Override parameters
python src/train.py trainer.max_epochs=20 data.batch_size=32

# Evaluate checkpoint
python src/eval.py ckpt_path="logs/train/runs/.../checkpoints/epoch_*.ckpt"

# Generate VIMH dataset
python generate_vimh.py --pickle --shuffle

# Audio evaluation (interactive)
python src/audio_reconstruction_eval.py interactive=true num_samples=5
```

## File Structure
```
├── src/
│   ├── train.py              # Main training
│   ├── eval.py               # Evaluation
│   ├── audio_reconstruction_eval.py  # Audio evaluation
│   ├── models/               # Lightning modules + components
│   ├── data/                 # VIMH data modules
│   └── utils/                # Synthesis utilities
├── configs/                  # Hydra configs
│   ├── experiment/           # Complete experiments
│   ├── model/                # Model architectures
│   ├── data/                 # Data configurations
│   └── trainer/              # Training configurations
├── tests/                    # Test suite
├── generate_vimh.py         # Dataset generation
└── data/                    # Generated datasets
```

## Expert Tips
- Use `trainer=mps` for Mac training (nearly always)
- Set `num_workers: 0` in data configs for MPS compatibility
- VIMH datasets auto-generate on first use
- Use `make format` before commits
- Check `make h` for all available targets
- TensorBoard runs on `http://localhost:6006`